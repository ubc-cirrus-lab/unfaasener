{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3982f75",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b197d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import shlex\n",
    "import datetime\n",
    "from sys import getsizeof\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756030fb",
   "metadata": {},
   "source": [
    "# Calling Workflow and Storing Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3927e364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import getsizeof\n",
    "class GetWorkflowLogs:\n",
    "    def __init__(self, workflow, messages, count, sleepTime, functions, initFunc):\n",
    "        self.initFunc = initFunc\n",
    "        self.count = count\n",
    "        self.msgExeDic = {}\n",
    "        self.workflow = workflow\n",
    "        self.messages = messages\n",
    "        self.functions = functions\n",
    "        self.messagesize = {}\n",
    "        self.sleepTime = sleepTime\n",
    "        self.timeDiff = []\n",
    "        self.execodes = []\n",
    "        self.allLogs ={}\n",
    "        self.writeLogs = {}\n",
    "        for func in self.functions:\n",
    "            self.allLogs[func] =[]\n",
    "            self.writeLogs[func] = []\n",
    "        self.subscriberExe = {}\n",
    "        self.publisherFinishedTime = {}\n",
    "        self.getLogPeriod = math.floor(1000 / (self.count*3))\n",
    "        self.finalWord = False\n",
    "        self.execute()\n",
    "\n",
    "    def execute(self):\n",
    "        self.getLogCounter = 0\n",
    "        for msg in self.messages:\n",
    "            if msg == self.messages[-1]:\n",
    "                self.finalWord = True\n",
    "            self.getLogCounter += 1\n",
    "            self.getLatency(msg)\n",
    "        self.saveResults()\n",
    "        print(\"Files are saved\")\n",
    "            \n",
    "\n",
    "        \n",
    "    def saveResults(self):\n",
    "        with open(os.getcwd()+\"/data/\"  + str(self.workflow)+ \", \"+str(self.count)+\", publisheExeIDs.json\", \"w\") as publisherExeID:\n",
    "            json.dump(self.execodes, publisherExeID)\n",
    "        with open(os.getcwd()+\"/data/\"  + str(self.workflow)+ \", \"+str(self.count)+\", messageExe.json\", \"w\") as publisherExeID:\n",
    "            json.dump(self.msgExeDic, publisherExeID)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    def getLatency(self, msg):\n",
    "        \n",
    "        self.callWorkflow(msg)\n",
    "        if((self.getLogCounter == self.getLogPeriod) or (self.finalWord == True)):\n",
    "            self.getLogCounter = 0\n",
    "            time.sleep(20)\n",
    "            self.getLogs()\n",
    "            if(self.finalWord == True):\n",
    "                print(\"Message \"+ msg+ \" with \"+ str(getsizeof(msg)) +\" bytes is called for \" + str(self.count) + \" times!\")\n",
    "\n",
    "            \n",
    "        \n",
    "         \n",
    "    def callWorkflow(self, msg):\n",
    "        for c in range(self.count):\n",
    "            res = subprocess.check_output(shlex.split(\"curl -X POST \\\"https://northamerica-northeast1-ubc-serverless-ghazal.cloudfunctions.net/\" + self.initFunc+\"\\\"\"  + \" --data '{\\\"message\\\":\\\"\" + (msg)+\"\\\", \\\"routing\\\":\\\"\" + \"0000000000\" + \"\\\"}' -H \\\"Content-Type:application/json\\\"\"))\n",
    "            resString = res.decode(\"utf-8\")\n",
    "            exeId = resString\n",
    "            print(\"-----------------\"+ str(c)+ \"-----------------\")\n",
    "            print(\"Execution ID: \" + exeId)\n",
    "#             self.msgExeDic[exeId] = str(getsizeof(msg))\n",
    "            self.msgExeDic[exeId] = msg\n",
    "            self.execodes.append(exeId)\n",
    "            time.sleep(self.sleepTime)\n",
    "        print(\"Workflow with Input: \"+ msg+ \" is triggered for \" + str(self.count) + \" times!\")\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    def getLogs(self):\n",
    "        for func in self.functions:\n",
    "            project_list_logs = \"gcloud functions logs read \"+ func +  \" --region northamerica-northeast1 --format json --limit 1000\"\n",
    "            project_logs = subprocess.check_output(shlex.split(project_list_logs))\n",
    "            project_logs_json = json.loads(project_logs)\n",
    "            (self.allLogs[func]).extend(project_logs_json)\n",
    "        if (self.finalWord == True):\n",
    "            for func in self.functions:\n",
    "                self.writeLogs[func]= self.allLogs[func]\n",
    "            with open(os.getcwd()+\"*path\" + str(self.workflow)+ \", \"+str(self.count)+ ', data.json', 'a') as outfile:\n",
    "                json.dump(self.writeLogs, outfile)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b9a9b2",
   "metadata": {},
   "source": [
    "### An Example for getting logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60e31b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow = workflowName\n",
    "# messages = [array of inputs]\n",
    "# workflowFunctions = [array of workflow functions]\n",
    "# initFunc = initial function of the workflow\n",
    "# sleepTime = between invocation of functions(sec)\n",
    "# count = number of invocations per each input\n",
    "# workflowObj = GetWorkflowLogs(workflow, messages, count, sleepTime, workflowFunctions, initFunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c227a18a",
   "metadata": {},
   "source": [
    "# Analyzing Logs and Retriving Data for each Function in the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbcbc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalyzeLogs:\n",
    "    def __init__(self, logsFile, publisherExeFile, msgExeFile, function, initFunc):\n",
    "            print(function)\n",
    "            self.initFunction = initFunc\n",
    "            self.function = function\n",
    "            self.timeDiff = []\n",
    "            self.messageSizeArray = []\n",
    "            self.execodes = []\n",
    "            self.reqIDs = []\n",
    "            self.reqMsgDic = {}\n",
    "            self.funcExecodes = []\n",
    "            self.latencyPerExeCode = {}\n",
    "            with open(logsFile) as json_file:\n",
    "                writeLogs = json.load(json_file)\n",
    "                self.logs = writeLogs[self.function]\n",
    "                self.initLogs = writeLogs[self.initFunction]\n",
    "            with open(publisherExeFile) as json_file:\n",
    "                self.execodes = json.load(json_file)\n",
    "            with open(msgExeFile) as json_file:\n",
    "                self.msgExe = json.load(json_file)\n",
    "            self.fetchReqIDs()\n",
    "            self.getData()\n",
    "            print(self.function + \" DONE\")\n",
    "        \n",
    "    \n",
    "\n",
    "    def fetchReqIDs(self):\n",
    "        for id in self.execodes:\n",
    "            for entry in self.initLogs:\n",
    "                    if(entry['execution_id'] == id and (\"WARNING:root:\" in entry['log']) ):\n",
    "                        reqID = entry['log'].replace(\"WARNING:root:\", \"\")\n",
    "                        self.reqIDs.append(reqID)\n",
    "                        self.reqMsgDic[reqID] = self.msgExe[id]\n",
    "                        break\n",
    "\n",
    "    def getData(self):\n",
    "        print(self.function)\n",
    "        data = {}\n",
    "        reqExeMap = {}\n",
    "        counter = 0\n",
    "        for id in self.reqIDs:\n",
    "            foundFlag = False\n",
    "            for entry in self.logs:\n",
    "                if entry['log'] is not None:\n",
    "                    if((\"WARNING:root:\"+id) in entry['log']):\n",
    "                        counter += 1\n",
    "                        self.funcExecodes.append(entry['execution_id'])\n",
    "                        reqExeMap[entry['execution_id']] = id\n",
    "                        foundFlag = True\n",
    "                        break\n",
    "            if foundFlag == False:\n",
    "                print(id+\" NOT FOUND\")\n",
    "        print(\"finalCounter: \"+ str(counter))\n",
    "        for id in self.funcExecodes:\n",
    "            data[reqExeMap[id]] = {}\n",
    "            data[reqExeMap[id]][\"message\"] = self.reqMsgDic[reqExeMap[id]]\n",
    "            for entry in self.logs:\n",
    "\n",
    "                if(entry['execution_id'] == id and (entry['log'] == \"Function execution started\") ):\n",
    "                    if entry['time_utc'].endswith('Z'):\n",
    "                        entry['time_utc'] = entry['time_utc'][:-1]+\".000\"\n",
    "                    dateStart = entry['time_utc']\n",
    "                    data[reqExeMap[id]][\"start\"]  = dateStart\n",
    "                elif (entry['execution_id'] == id and (\"finished with status\" in entry['log']) ):\n",
    "                    if entry['time_utc'].endswith('Z'):\n",
    "                        entry['time_utc'] = entry['time_utc'][:-1]+\".000\"\n",
    "                    dateFinish = entry['time_utc']\n",
    "                    data[reqExeMap[id]][\"finish\"]  = dateFinish\n",
    "        print(len(data))\n",
    "        with open(os.getcwd()+\"*path\" +str(self.function)+', data.json', 'a') as outfile:\n",
    "            json.dump(data, outfile)  \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df2904c",
   "metadata": {},
   "source": [
    "### An Example for retrieving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccae56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogsPath = \"path to storeed logs\"\n",
    "# ExeIDPath = \"path to exe ids\"\n",
    "# msgExePath = \"path to stored exe IDs, msg dict\"\n",
    "# initFunc = \"name of first function in the workflow\"\n",
    "# for func in workflowFunctions:\n",
    "#     AnalyzeLogsObj = AnalyzeLogs(LogsPath, ExeIDPath, msgExePath, func, initFunc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76978f92",
   "metadata": {},
   "source": [
    "## Merging data from all functions in the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30c33c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = [array of prev stored paths]\n",
    "\n",
    "# data = {}\n",
    "# for path in paths:\n",
    "#     with open(path) as json_file:\n",
    "#         data[(path.split(\"/\")[-1]).split(\",\")[0]]=(json.load(json_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b3fea9",
   "metadata": {},
   "source": [
    "# Generating DataFrame from the Retrieved Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2f8722",
   "metadata": {},
   "outputs": [],
   "source": [
    "reqIDs = []\n",
    "inputs=[]\n",
    "func1S = []\n",
    "generatedData={}\n",
    "generatedData2={}\n",
    "# successors = [array of array of successors]\n",
    "\n",
    "for req in data[initFunc]:\n",
    "    reqIDs.append(req)\n",
    "    inputs.append(data[initFunc][req]['message'])\n",
    "generatedData[\"reqID\"] = reqIDs\n",
    "generatedData[\"inputs\"] = inputs\n",
    "for func in workflowFunctions:\n",
    "    generatedData2[func+\"-Start\"] = []\n",
    "    generatedData2[func+\"-Finish\"] = []\n",
    "    generatedData[func] = []\n",
    "    newData = data[func]\n",
    "    for req in reqIDs:\n",
    "        start = newData[req][\"start\"]\n",
    "        start = datetime.datetime.strptime(start, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "        generatedData2[func+\"-Start\"].append(start)\n",
    "        finish = newData[req][\"finish\"]\n",
    "        finish = datetime.datetime.strptime(finish, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "        generatedData2[func+\"-Finish\"].append(finish)\n",
    "        difference = finish - start\n",
    "        generatedData[func].append(difference.microseconds/1000)\n",
    "\n",
    "\n",
    "for func in workflowFunctions:\n",
    "    for successor in successors[workflowFunctions.index(func)]:\n",
    "        generatedData [func+\"-\"+successor] = [((a_i - b_i).microseconds/1000) for a_i, b_i in zip(generatedData2[successor+\"-Start\"], generatedData2[func+\"-Finish\"])]\n",
    "        \n",
    "        \n",
    "print(generatedData)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed9d65c",
   "metadata": {},
   "source": [
    "### Storing datarframe in pickle format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a713af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(os.getcwd()+\"*path\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
